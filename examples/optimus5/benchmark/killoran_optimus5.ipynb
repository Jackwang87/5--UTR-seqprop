{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import itertools\n",
    "from keras.layers import Input, Dense, Reshape, Flatten\n",
    "from keras import layers, initializers\n",
    "from keras.models import Model, load_model\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "import json\n",
    "#import tensorflow_probability as tfp\n",
    "\n",
    "#tfd = tfp.distributions\n",
    "\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "def contain_tf_gpu_mem_usage() :\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    sess = tf.Session(config=config)\n",
    "    set_session(sess)\n",
    "\n",
    "contain_tf_gpu_mem_usage()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "\n",
    "#Stochastic Binarized Neuron helper functions (Tensorflow)\n",
    "#ST Estimator code adopted from https://r2rt.com/beyond-binary-ternary-and-one-hot-neurons.html\n",
    "#See Github https://github.com/spitis/\n",
    "\n",
    "def st_sampled_softmax(logits):\n",
    "    with ops.name_scope(\"STSampledSoftmax\") as namescope :\n",
    "        nt_probs = tf.nn.softmax(logits)\n",
    "        onehot_dim = logits.get_shape().as_list()[1]\n",
    "        sampled_onehot = tf.one_hot(tf.squeeze(tf.multinomial(logits, 1), 1), onehot_dim, 1.0, 0.0)\n",
    "        with tf.get_default_graph().gradient_override_map({'Ceil': 'Identity', 'Mul': 'STMul'}):\n",
    "            return tf.ceil(sampled_onehot * nt_probs)\n",
    "\n",
    "def st_hardmax_softmax(logits):\n",
    "    with ops.name_scope(\"STHardmaxSoftmax\") as namescope :\n",
    "        nt_probs = tf.nn.softmax(logits)\n",
    "        onehot_dim = logits.get_shape().as_list()[1]\n",
    "        sampled_onehot = tf.one_hot(tf.argmax(nt_probs, 1), onehot_dim, 1.0, 0.0)\n",
    "        with tf.get_default_graph().gradient_override_map({'Ceil': 'Identity', 'Mul': 'STMul'}):\n",
    "            return tf.ceil(sampled_onehot * nt_probs)\n",
    "\n",
    "@ops.RegisterGradient(\"STMul\")\n",
    "def st_mul(op, grad):\n",
    "    return [grad, grad]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load models\n",
    "\n",
    "vae_path = \"../vae/saved_models/vae_optimus5_strong_len_54_latent_100_epochs_50_kl_factor_15_annealed_high_rc\"\n",
    "\n",
    "predictor_path = '../evolution_model.hdf5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import isolearn.io as isoio\n",
    "import isolearn.keras as isol\n",
    "\n",
    "encoder = isol.OneHotEncoder(seq_length=54)\n",
    "\n",
    "def initialize_sequence_templates(sequence_template, encoder=encoder) :\n",
    "\n",
    "    onehot_template = encoder(sequence_template).reshape((1, len(sequence_template), 4, 1))\n",
    "\n",
    "    for j in range(len(sequence_template)) :\n",
    "        if sequence_template[j] != 'N' :\n",
    "            nt_ix = np.argmax(onehot_template[0, j, :, 0])\n",
    "            onehot_template[0, j, :, :] = 0\n",
    "            onehot_template[0, j, nt_ix, :] = 1\n",
    "        else :\n",
    "            onehot_template[0, j, :, :] = 0\n",
    "\n",
    "    onehot_mask = np.zeros((1, len(sequence_template), 4, 1))\n",
    "    for j in range(len(sequence_template)) :\n",
    "        if sequence_template[j] == 'N' :\n",
    "            onehot_mask[0, j, :, :] = 1.0\n",
    "\n",
    "    return onehot_template, onehot_mask\n",
    "\n",
    "sequence_template = 'N' * 50 + 'ATGG'\n",
    "\n",
    "template_mat, mask_mat = initialize_sequence_templates(sequence_template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def killoran_opt(vae_decoder, oracle,\n",
    "                 steps=20000, store_every1=5, store_every2=100, store_swap_iter=100, epsilon1=10**-5, epsilon2=1, noise_std=10**-5, save_path=None,\n",
    "                 LD=100, verbose=False, adam=False, template_mat=template_mat, mask_mat=mask_mat, encoder=encoder):\n",
    "    \n",
    "    G = vae_decoder\n",
    "    f = oracle\n",
    "    \n",
    "    sess = K.get_session()\n",
    "    zt = K.tf.Variable(np.random.normal(size=[1, LD]), dtype='float32')\n",
    "    zt_dummy = K.tf.Variable(np.zeros((1, 1)), trainable=False, dtype='float32')\n",
    "    \n",
    "    pred_input = K.tf.Variable(np.zeros((1, 54, 4, 1)), dtype='float32')\n",
    "    \n",
    "    template = K.tf.Variable(template_mat, trainable=False, dtype='float32')\n",
    "    mask = K.tf.Variable(mask_mat, trainable=False, dtype='float32')\n",
    "    \n",
    "    gen_output = K.tf.transpose(G([zt_dummy, zt])[1], (0, 2, 3, 1)) * mask + template\n",
    "    #prior = tfd.Normal(0, 1)\n",
    "    #p_z = prior.log_prob(zt)\n",
    "    \n",
    "    predictions = f(pred_input)[0, 0]\n",
    "    update_pred_input = K.tf.assign(pred_input, gen_output)\n",
    "    dfdx = K.tf.gradients(ys=-predictions, xs=pred_input)[0]\n",
    "    dfdz = K.tf.gradients(gen_output, zt, grad_ys=dfdx)[0]\n",
    "    #dpz = K.tf.gradients(p_z, zt)[0]\n",
    "    \n",
    "    noise = K.tf.random_normal(shape=[1, LD], stddev=noise_std)\n",
    "    eps1 = K.tf.Variable(epsilon1, trainable=False)\n",
    "    eps2 = K.tf.Variable(epsilon2, trainable=False)\n",
    "    if adam:\n",
    "        optimizer = K.tf.train.AdamOptimizer(learning_rate=epsilon2)\n",
    "        step = dfdz + noise\n",
    "    else:\n",
    "        optimizer = K.tf.train.GradientDescentOptimizer(learning_rate=1)\n",
    "        step = eps1 * dpz + eps2 * dfdz + noise\n",
    "    \n",
    "    design_op = optimizer.apply_gradients([(step, zt)])\n",
    "    adam_initializers = [var.initializer for var in K.tf.global_variables() if 'Adam' in var.name or 'beta' in var.name]\n",
    "    sess.run(adam_initializers)\n",
    "    sess.run(pred_input.initializer)\n",
    "    sess.run(zt.initializer)\n",
    "    sess.run(eps1.initializer)\n",
    "    sess.run(eps2.initializer)\n",
    "    \n",
    "    sess.run(zt_dummy.initializer)\n",
    "    sess.run(pred_input.initializer)\n",
    "    sess.run(template.initializer)\n",
    "    sess.run(mask.initializer)\n",
    "    \n",
    "    s = sess.run(K.tf.shape(zt))\n",
    "    sess.run(update_pred_input, {\n",
    "        zt: np.random.normal(size=s),\n",
    "        zt_dummy: np.zeros((1, 1)),\n",
    "        template: template_mat,\n",
    "        mask: mask_mat\n",
    "    })\n",
    "    z_0 = sess.run([zt])\n",
    "    \n",
    "    store_every = store_every1\n",
    "    \n",
    "    xt_prev = None\n",
    "    for t in range(steps):\n",
    "        if t % 1000 == 0 :\n",
    "            print(\"Running step \" + str(t) + \"...\")\n",
    "        \n",
    "        if t > store_swap_iter :\n",
    "            store_every = store_every2\n",
    "        \n",
    "        xt0, _, = sess.run([gen_output, design_op], {eps1: epsilon1, eps2:epsilon2})\n",
    "        pred_in, preds = sess.run([update_pred_input, predictions])\n",
    "        \n",
    "        nt_map_inv = {0:'A', 1:'C', 2:'G', 3:'T'}\n",
    "        \n",
    "        xt_seq = ''\n",
    "        for j in range(xt0.shape[1]) :\n",
    "            argmax_j = np.argmax(xt0[0, j, :, 0])\n",
    "            xt_seq += nt_map_inv[argmax_j]\n",
    "        \n",
    "        if save_path is not None and t % store_every == 0 :\n",
    "            with open(save_path + \"_iter_\" + str(t) + \".txt\", \"a+\") as f :\n",
    "                f.write(xt_seq + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input, Lambda\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv1D, MaxPooling1D, LSTM, ConvLSTM2D, GRU, BatchNormalization, LocallyConnected2D, Permute\n",
    "from keras.layers import Concatenate, Reshape, Softmax, Conv2DTranspose, Embedding, Multiply\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "import keras.losses\n",
    "\n",
    "def _load_optimus5_func(model_path) :\n",
    "\n",
    "    seq_input = Input(shape=(54, 4, 1), name='seq_input')\n",
    "    \n",
    "    #Define permute layer\n",
    "    permute_input = Lambda(lambda x: x[..., 0])\n",
    "\n",
    "    optimus5 = load_model(model_path)\n",
    "\n",
    "    #Execute functional model definition\n",
    "    _oracle = Model([seq_input], optimus5([permute_input(seq_input)]))\n",
    "    \n",
    "    _oracle.trainable=False\n",
    "    _oracle.compile(\n",
    "        optimizer=keras.optimizers.SGD(lr=0.1), loss='mean_squared_error'\n",
    "    )\n",
    "    \n",
    "    return _oracle\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_killoran(n_traj=5, steps=20000, vae_prefix_str=\"\", vae_path=vae_path, predictor_path=predictor_path):\n",
    "    \n",
    "    for i in range(n_traj):\n",
    "        RANDOM_STATE = i+1\n",
    "        print(RANDOM_STATE)\n",
    "        \n",
    "        sess = tf.Session(graph=tf.get_default_graph())\n",
    "        K.set_session(sess)\n",
    "        \n",
    "        #Load models\n",
    "        oracle = _load_optimus5_func(predictor_path)\n",
    "\n",
    "        #encoder = load_model(vae_path + '_encoder.h5', custom_objects={'st_sampled_softmax':st_sampled_softmax, 'st_hardmax_softmax':st_hardmax_softmax, 'min_pred':lambda y_true,y_pred:y_pred})\n",
    "        decoder = load_model(vae_path + '_decoder.h5', custom_objects={'st_sampled_softmax':st_sampled_softmax, 'st_hardmax_softmax':st_hardmax_softmax, 'min_pred':lambda y_true,y_pred:y_pred})\n",
    "        \n",
    "        killoran_opt(decoder, oracle, steps=steps, epsilon1=0., epsilon2=0.1,  \n",
    "                                     noise_std=1e-6, store_every1=5, store_every2=100, store_swap_iter=100,\n",
    "                                     LD=100, verbose=False, adam=True,\n",
    "                                     save_path='killoran/killoran_vae' + vae_prefix_str + '_optimus5_seqs'\n",
    "                            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From <ipython-input-2-7011d93d8e2f>:11: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.random.categorical instead.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Running step 0...\n",
      "Running step 1000...\n",
      "2\n",
      "Running step 0...\n",
      "Running step 1000...\n",
      "3\n",
      "Running step 0...\n",
      "Running step 1000...\n",
      "4\n",
      "Running step 0...\n",
      "Running step 1000...\n",
      "5\n",
      "Running step 0...\n",
      "Running step 1000...\n",
      "6\n",
      "Running step 0...\n",
      "Running step 1000...\n",
      "7\n",
      "Running step 0...\n",
      "Running step 1000...\n",
      "8\n",
      "Running step 0...\n",
      "Running step 1000...\n",
      "9\n",
      "Running step 0...\n",
      "Running step 1000...\n",
      "10\n",
      "Running step 0...\n",
      "Running step 1000...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "run_killoran(n_traj=10, steps=2000, vae_prefix_str=\"_epochs_50_kl_factor_15\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
