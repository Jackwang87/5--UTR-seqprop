{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import itertools\n",
    "from keras.layers import Input, Dense, Reshape, Flatten\n",
    "from keras import layers, initializers\n",
    "from keras.models import Model, load_model\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "import json\n",
    "#import tensorflow_probability as tfp\n",
    "\n",
    "#tfd = tfp.distributions\n",
    "\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "def contain_tf_gpu_mem_usage() :\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    sess = tf.Session(config=config)\n",
    "    set_session(sess)\n",
    "\n",
    "contain_tf_gpu_mem_usage()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "\n",
    "#Stochastic Binarized Neuron helper functions (Tensorflow)\n",
    "#ST Estimator code adopted from https://r2rt.com/beyond-binary-ternary-and-one-hot-neurons.html\n",
    "#See Github https://github.com/spitis/\n",
    "\n",
    "def st_sampled_softmax(logits):\n",
    "    with ops.name_scope(\"STSampledSoftmax\") as namescope :\n",
    "        nt_probs = tf.nn.softmax(logits)\n",
    "        onehot_dim = logits.get_shape().as_list()[1]\n",
    "        sampled_onehot = tf.one_hot(tf.squeeze(tf.multinomial(logits, 1), 1), onehot_dim, 1.0, 0.0)\n",
    "        with tf.get_default_graph().gradient_override_map({'Ceil': 'Identity', 'Mul': 'STMul'}):\n",
    "            return tf.ceil(sampled_onehot * nt_probs)\n",
    "\n",
    "def st_hardmax_softmax(logits):\n",
    "    with ops.name_scope(\"STHardmaxSoftmax\") as namescope :\n",
    "        nt_probs = tf.nn.softmax(logits)\n",
    "        onehot_dim = logits.get_shape().as_list()[1]\n",
    "        sampled_onehot = tf.one_hot(tf.argmax(nt_probs, 1), onehot_dim, 1.0, 0.0)\n",
    "        with tf.get_default_graph().gradient_override_map({'Ceil': 'Identity', 'Mul': 'STMul'}):\n",
    "            return tf.ceil(sampled_onehot * nt_probs)\n",
    "\n",
    "@ops.RegisterGradient(\"STMul\")\n",
    "def st_mul(op, grad):\n",
    "    return [grad, grad]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load models\n",
    "\n",
    "vae_path = \"../vae/saved_models/vae_apa_max_isoform_simple_strong_len_96_latent_100_epochs_50_kl_factor_1125_annealed\"\n",
    "\n",
    "predictor_path = '../../../../aparent/saved_models/aparent_plasmid_iso_cut_distalpas_all_libs_no_sampleweights_sgd.h5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import isolearn.io as isoio\n",
    "import isolearn.keras as isol\n",
    "\n",
    "encoder = isol.OneHotEncoder(seq_length=205)\n",
    "\n",
    "def initialize_sequence_templates(sequence_template, encoder=encoder) :\n",
    "\n",
    "    onehot_template = encoder(sequence_template).reshape((1, len(sequence_template), 4, 1))\n",
    "\n",
    "    for j in range(len(sequence_template)) :\n",
    "        if sequence_template[j] != 'N' :\n",
    "            nt_ix = np.argmax(onehot_template[0, j, :, 0])\n",
    "            onehot_template[0, j, :, :] = 0\n",
    "            onehot_template[0, j, nt_ix, :] = 1\n",
    "        else :\n",
    "            onehot_template[0, j, :, :] = 0\n",
    "\n",
    "    onehot_mask = np.zeros((1, len(sequence_template), 4, 1))\n",
    "    for j in range(len(sequence_template)) :\n",
    "        if sequence_template[j] == 'N' :\n",
    "            onehot_mask[0, j, :, :] = 1.0\n",
    "\n",
    "    return onehot_template, onehot_mask\n",
    "\n",
    "sequence_template = 'TCCCTACACGACGCTCTTCCGATCTNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNANTAAANNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNAATAAATTGTTCGTTGGTCGGCTTGAGTGCGTGTGTCTCGTTTAGATGCTGCGCCTAACCCTAAGCAGATTCTTCATGCAATTG'\n",
    "\n",
    "template_mat, mask_mat = initialize_sequence_templates(sequence_template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def killoran_opt(vae_decoder, oracle,\n",
    "                 steps=20000, store_every1=5, store_every2=100, store_swap_iter=100, epsilon1=10**-5, epsilon2=1, noise_std=10**-5, save_path=None,\n",
    "                 LD=100, verbose=False, adam=False, template_mat=template_mat, mask_mat=mask_mat, encoder=encoder):\n",
    "    \n",
    "    G = vae_decoder\n",
    "    f = oracle\n",
    "    \n",
    "    sess = K.get_session()\n",
    "    zt = K.tf.Variable(np.random.normal(size=[1, LD]), dtype='float32')\n",
    "    zt_dummy = K.tf.Variable(np.zeros((1, 1)), trainable=False, dtype='float32')\n",
    "    \n",
    "    lib_simple = np.zeros((1, 13))\n",
    "    lib_simple[0, 5] = 1.\n",
    "    \n",
    "    pred_input = K.tf.Variable(np.zeros((1, 205, 4, 1)), dtype='float32')\n",
    "    lib_input = K.tf.Variable(lib_simple, trainable=False, dtype='float32')\n",
    "    lib_distal = K.tf.Variable(np.ones((1, 1)), trainable=False, dtype='float32')\n",
    "    \n",
    "    template = K.tf.Variable(template_mat, trainable=False, dtype='float32')\n",
    "    mask = K.tf.Variable(mask_mat, trainable=False, dtype='float32')\n",
    "    \n",
    "    left_pad = K.tf.Variable(np.zeros((1, 25, 4, 1)), trainable=False, dtype='float32')\n",
    "    right_pad = K.tf.Variable(np.zeros((1, 84, 4, 1)), trainable=False, dtype='float32')\n",
    "    \n",
    "    gen_output = K.tf.concat([left_pad, K.tf.transpose(G([zt_dummy, zt])[1], (0, 2, 3, 1)), right_pad], axis=1) * mask + template\n",
    "    #prior = tfd.Normal(0, 1)\n",
    "    #p_z = prior.log_prob(zt)\n",
    "    \n",
    "    predictions = f([pred_input, lib_input, lib_distal])[0][0, 0]\n",
    "    update_pred_input = K.tf.assign(pred_input, gen_output)\n",
    "    dfdx = K.tf.gradients(ys=-predictions, xs=pred_input)[0]\n",
    "    dfdz = K.tf.gradients(gen_output, zt, grad_ys=dfdx)[0]\n",
    "    #dpz = K.tf.gradients(p_z, zt)[0]\n",
    "    \n",
    "    noise = K.tf.random_normal(shape=[1, LD], stddev=noise_std)\n",
    "    eps1 = K.tf.Variable(epsilon1, trainable=False)\n",
    "    eps2 = K.tf.Variable(epsilon2, trainable=False)\n",
    "    if adam:\n",
    "        optimizer = K.tf.train.AdamOptimizer(learning_rate=epsilon2)\n",
    "        step = dfdz + noise\n",
    "    else:\n",
    "        optimizer = K.tf.train.GradientDescentOptimizer(learning_rate=1)\n",
    "        step = eps1 * dpz + eps2 * dfdz + noise\n",
    "    \n",
    "    design_op = optimizer.apply_gradients([(step, zt)])\n",
    "    adam_initializers = [var.initializer for var in K.tf.global_variables() if 'Adam' in var.name or 'beta' in var.name]\n",
    "    sess.run(adam_initializers)\n",
    "    sess.run(pred_input.initializer)\n",
    "    sess.run(zt.initializer)\n",
    "    sess.run(eps1.initializer)\n",
    "    sess.run(eps2.initializer)\n",
    "    \n",
    "    sess.run(zt_dummy.initializer)\n",
    "    sess.run(pred_input.initializer)\n",
    "    sess.run(lib_input.initializer)\n",
    "    sess.run(lib_distal.initializer)\n",
    "    sess.run(template.initializer)\n",
    "    sess.run(mask.initializer)\n",
    "    sess.run(left_pad.initializer)\n",
    "    sess.run(right_pad.initializer)\n",
    "    \n",
    "    s = sess.run(K.tf.shape(zt))\n",
    "    sess.run(update_pred_input, {\n",
    "        zt: np.random.normal(size=s),\n",
    "        zt_dummy: np.zeros((1, 1)),\n",
    "        lib_input: lib_simple,\n",
    "        lib_distal: np.ones((1, 1)),\n",
    "        template: template_mat,\n",
    "        mask: mask_mat,\n",
    "        left_pad: np.zeros((1, 25, 4, 1)),\n",
    "        right_pad: np.zeros((1, 84, 4, 1))\n",
    "    })\n",
    "    z_0 = sess.run([zt])\n",
    "    \n",
    "    store_every = store_every1\n",
    "    \n",
    "    xt_prev = None\n",
    "    for t in range(steps):\n",
    "        if t % 1000 == 0 :\n",
    "            print(\"Running step \" + str(t) + \"...\")\n",
    "        \n",
    "        if t > store_swap_iter :\n",
    "            store_every = store_every2\n",
    "        \n",
    "        xt0, _, = sess.run([gen_output, design_op], {eps1: epsilon1, eps2:epsilon2})\n",
    "        pred_in, preds = sess.run([update_pred_input, predictions])\n",
    "        \n",
    "        nt_map_inv = {0:'A', 1:'C', 2:'G', 3:'T'}\n",
    "        \n",
    "        xt_seq = ''\n",
    "        for j in range(xt0.shape[1]) :\n",
    "            argmax_j = np.argmax(xt0[0, j, :, 0])\n",
    "            xt_seq += nt_map_inv[argmax_j]\n",
    "        \n",
    "        if save_path is not None and t % store_every == 0 :\n",
    "            with open(save_path + \"_iter_\" + str(t) + \".txt\", \"a+\") as f :\n",
    "                f.write(xt_seq + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input, Lambda\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv1D, MaxPooling1D, LSTM, ConvLSTM2D, GRU, BatchNormalization, LocallyConnected2D, Permute\n",
    "from keras.layers import Concatenate, Reshape, Softmax, Conv2DTranspose, Embedding, Multiply\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "import keras.losses\n",
    "\n",
    "def _load_aparent_func(model_path) :\n",
    "\n",
    "    seq_input = Input(shape=(205, 4, 1), name='seq_input')\n",
    "    lib_input = Input(shape=(13,), name='lib_input')\n",
    "    distal_pas_input = Input(shape=(1,), name='distal_pas_input')\n",
    "    \n",
    "    #Shared model definition\n",
    "    layer_1 = Conv2D(96, (8, 4), padding='valid', activation='relu', name='aparent_conv_1')\n",
    "    layer_1_pool = MaxPooling2D(pool_size=(2, 1))\n",
    "    layer_2 = Conv2D(128, (6, 1), padding='valid', activation='relu', name='aparent_conv_2')\n",
    "    layer_dense = Dense(256, activation='relu', name='aparent_dense_1')#(Concatenate()([Flatten()(layer_2), distal_pas_input]))\n",
    "    layer_drop = Dropout(0.2)\n",
    "\n",
    "    def shared_model(seq_input, distal_pas_input) :\n",
    "        return layer_drop(\n",
    "            layer_dense(\n",
    "                Concatenate()([\n",
    "                    Flatten()(\n",
    "                        layer_2(\n",
    "                            layer_1_pool(\n",
    "                                layer_1(\n",
    "                                    seq_input\n",
    "                                )\n",
    "                            )\n",
    "                        )\n",
    "                    ),\n",
    "                    distal_pas_input\n",
    "                ])\n",
    "            ), training=False\n",
    "        )\n",
    "\n",
    "\n",
    "    #Outputs\n",
    "    plasmid_out_shared = Concatenate()([shared_model(seq_input, distal_pas_input), lib_input])\n",
    "\n",
    "    plasmid_score_cut = Dense(206, kernel_initializer='zeros', name='aparent_cut_dense')(plasmid_out_shared)\n",
    "    plasmid_score_iso = Dense(1, kernel_initializer='zeros', name='aparent_iso_dense')(plasmid_out_shared)\n",
    "\n",
    "    plasmid_out_cut = Softmax(axis=-1)(plasmid_score_cut)\n",
    "    plasmid_out_iso = Dense(1, activation='sigmoid', kernel_initializer='ones', use_bias=False)(plasmid_score_iso)\n",
    "\n",
    "    _oracle = Model([seq_input, lib_input, distal_pas_input], [plasmid_score_iso, plasmid_score_cut, plasmid_out_iso, plasmid_out_cut])\n",
    "    \n",
    "    _saved_model = load_model(model_path)\n",
    "    _oracle.get_layer('aparent_conv_1').set_weights(_saved_model.get_layer('conv2d_1').get_weights())\n",
    "    _oracle.get_layer('aparent_conv_1').trainable = False\n",
    "\n",
    "    _oracle.get_layer('aparent_conv_2').set_weights(_saved_model.get_layer('conv2d_2').get_weights())\n",
    "    _oracle.get_layer('aparent_conv_2').trainable = False\n",
    "\n",
    "    _oracle.get_layer('aparent_dense_1').set_weights(_saved_model.get_layer('dense_1').get_weights())\n",
    "    _oracle.get_layer('aparent_dense_1').trainable = False\n",
    "\n",
    "    _oracle.get_layer('aparent_cut_dense').set_weights(_saved_model.get_layer('dense_2').get_weights())\n",
    "    _oracle.get_layer('aparent_cut_dense').trainable = False\n",
    "\n",
    "    _oracle.get_layer('aparent_iso_dense').set_weights(_saved_model.get_layer('dense_3').get_weights())\n",
    "    _oracle.get_layer('aparent_iso_dense').trainable = False\n",
    "\n",
    "    _oracle.trainable=False\n",
    "    _oracle.compile(\n",
    "        optimizer=keras.optimizers.SGD(lr=0.1), loss='mean_squared_error'\n",
    "    )\n",
    "    \n",
    "    return _oracle\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_killoran(n_traj=5, steps=20000, vae_prefix_str=\"\", vae_path=vae_path, predictor_path=predictor_path):\n",
    "    \n",
    "    for i in range(n_traj):\n",
    "        RANDOM_STATE = i+1\n",
    "        print(RANDOM_STATE)\n",
    "        \n",
    "        sess = tf.Session(graph=tf.get_default_graph())\n",
    "        K.set_session(sess)\n",
    "        \n",
    "        #Load models\n",
    "        #oracle = load_model(predictor_path)\n",
    "        oracle = _load_aparent_func(predictor_path)\n",
    "\n",
    "        #encoder = load_model(vae_path + '_encoder.h5', custom_objects={'st_sampled_softmax':st_sampled_softmax, 'st_hardmax_softmax':st_hardmax_softmax, 'min_pred':lambda y_true,y_pred:y_pred})\n",
    "        decoder = load_model(vae_path + '_decoder.h5', custom_objects={'st_sampled_softmax':st_sampled_softmax, 'st_hardmax_softmax':st_hardmax_softmax, 'min_pred':lambda y_true,y_pred:y_pred})\n",
    "        \n",
    "        killoran_opt(decoder, oracle, steps=steps, epsilon1=0., epsilon2=0.1,  \n",
    "                                     noise_std=1e-6, store_every1=5, store_every2=100, store_swap_iter=100,\n",
    "                                     LD=100, verbose=False, adam=True,\n",
    "                                     save_path='killoran/killoran_vae' + vae_prefix_str + '_apa_seqs'\n",
    "                            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Running step 0...\n",
      "Running step 1000...\n",
      "2\n",
      "Running step 0...\n",
      "Running step 1000...\n",
      "3\n",
      "Running step 0...\n",
      "Running step 1000...\n",
      "4\n",
      "Running step 0...\n",
      "Running step 1000...\n",
      "5\n",
      "Running step 0...\n",
      "Running step 1000...\n",
      "6\n",
      "Running step 0...\n",
      "Running step 1000...\n",
      "7\n",
      "Running step 0...\n",
      "Running step 1000...\n",
      "8\n",
      "Running step 0...\n",
      "Running step 1000...\n",
      "9\n",
      "Running step 0...\n",
      "Running step 1000...\n",
      "10\n",
      "Running step 0...\n",
      "Running step 1000...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "run_killoran(n_traj=10, steps=2000, vae_prefix_str=\"_epochs_50_kl_factor_1125\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
